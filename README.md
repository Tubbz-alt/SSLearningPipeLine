SSLearningPipeLine
---------

Script that provides the basic functionality for labeling user data data by
crawling through an image directory, displaying the image to the user, and then
saving the inputted label in an output directory.

Initial Setup
-------

SSH to a machine that has internet access. If you are on NFS, pslogin or any
of the psbuild-rhel<#> machines are accessible and have an internet connection.

```
ssh pslogin			# Or machine that has internet access
```

Set up a working directory.

```
mkdir work
cd work
```

Clone the SSLearningPipeline repo and the pylabelme repo into this working
directory.

```
git clone https://github.com/slaclab/SSLearningPipeLine.git
git clone https://github.com/slaclab/PyLabelMe.git
```

Operations
------

To have access to the data, SSH to one of the psana nodes.

```
ssh psana
```

Navigate to the working directory that contains SSLearningPipeline

```
cd work/SSLearningPipeLine
```

The script of interest is *user_driver.sh*, which provides the command line
interface to the labeling script. To actually begin running the script and
labelling images, it can be run as a stand alone executable.

```
./user_driver.sh
```

To view the list of options the script takes, run it with the *-h* or the
*--help* option.

```
./user_driver.sh -h
```

This command should return a summary of all the valid options avaliable and
looks as follows.

```
usage: user_driver.py [-h] [-v] [-d] [-e E] [-r N] [-m MODEL] [--logdir P]
                      [-o P] [-i P]

Display time tool results and receive input.

optional arguments:
  -h, --help            show this help message and exit
  -v, --verbose         Increase verbosity.
  -d, --debug           Run in debug mode.
  -e E, --experiment E  Experiment to run the labeler with.
  -r N, --run N         Run number of the experiment.
  -m MODEL, --model MODEL
                        Regression model to be used.
  --logdir P            Path to save the logs in.
  -o P, --output P      Path to save the labeled images in.
  -i P, --images P      Path to get the images from.
```

Legacy Variable Definitions
----------

vgg16 weights:
  
 - These are very important. These weights are the weights of the VGGNET model which we past each image through to get codewords. These     codewords will be the our feature set for any machine learning ( as simple as linear regression) task we want to do.

json directory:
    
 - After labeling an image, the locations of the boxes drawn and their corresponding labels are stored in a json file. From the json       files of the labeled images we create machine learning models.
    
codewords:
    
 - Once again these codewords are generated by passing the images through the vgg net. 

index list:
  
 - This is just a predefined list of images that we will be looking at. From this list of indexes we can gather the images from the the     corresponding experiment's database.
  
dark image:

 - This is an image which represents what the camera sees when there is no action going on. It is important to subtract this from the       images so we can see the image that corresponds to the real action. This perhaps was a bit to figurative of an explanation.
